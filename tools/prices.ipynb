{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "download_names_list = []\n",
    "\n",
    "start_year_zip = 2018\n",
    "start_date = \"20230101\"\n",
    "end_date = \"20241220\"\n",
    "\n",
    "name_list = []\n",
    "current_date = datetime.strptime(start_date, \"%Y%m%d\")\n",
    "end_date_datetime = datetime.strptime(end_date, \"%Y%m%d\")\n",
    "\n",
    "while current_date <= end_date_datetime:\n",
    "    name_list.append(current_date.strftime(\"%Y%m%d\"))\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "for date in name_list:\n",
    "    download_names_list.append(f\"{date}\")\n",
    "\n",
    "years = range(start_year_zip, 2023)\n",
    "for year in years:\n",
    "    download_names_list.append(f\"{year}.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def download_file_with_versions(session, base_url, name):\n",
    "    \"\"\"\n",
    "    Attempt to download a file for a given name.\n",
    "    If the name ends with '.zip', download it directly.\n",
    "    Otherwise, try versions .1 to .6.\n",
    "    Returns the first successfully downloaded file's content or None if all fail.\n",
    "    \"\"\"\n",
    "    # Check if the name ends with '.zip'\n",
    "    if name.endswith(\".zip\"):\n",
    "        file_name = name\n",
    "        url = base_url + file_name\n",
    "        try:\n",
    "            headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Add headers if needed\n",
    "            async with session.get(url, headers=headers) as response:\n",
    "                if response.status == 200:\n",
    "                    # Successfully downloaded\n",
    "                    content = await response.read()\n",
    "                    return file_name, content\n",
    "                else:\n",
    "                    print(f\"Failed to download {url} with status {response.status}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {url}: {e}\")\n",
    "        # If the .zip file fails, return None\n",
    "        return None, None\n",
    "\n",
    "    # If not a .zip file, try versions .1 to .6\n",
    "    for version in range(1, 10):  # Try versions .1 to .6\n",
    "        file_name = f\"{name}.{version}\"\n",
    "        url = base_url + file_name\n",
    "        try:\n",
    "            headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Add headers if needed\n",
    "            async with session.get(url, headers=headers) as response:\n",
    "                if response.status == 200:\n",
    "                    # Successfully downloaded\n",
    "                    content = await response.read()\n",
    "                    return file_name, content\n",
    "                else:\n",
    "                    print(f\"Skipped {file_name}. Fetching version {version+1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {url}: {e}\")\n",
    "    # If all versions fail, return None\n",
    "    raise ValueError(f\"Failed to download {name}\")\n",
    "\n",
    "async def download_all_files(base_url, name_list):\n",
    "    \"\"\"\n",
    "    Download all files for the given dates, trying versions .1 to .6 for each name.\n",
    "    Returns a dictionary with file names as keys and content as values.\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_file_with_versions(session, base_url, name) for name in name_list]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        # Print failed downloads\n",
    "        for file_name, content in results:\n",
    "            if content is None:\n",
    "                print(f\"Failed to download any version for {file_name}\")\n",
    "        # Create a dictionary from the results, filtering out failed downloads (None values)\n",
    "        return {file_name: content for file_name, content in results if content is not None}\n",
    "\n",
    "# Example usage\n",
    "base_url = \"https://www.omie.es/pt/file-download?parents=marginalpdbcpt&filename=marginalpdbcpt_\" # diario\n",
    "# base_url = \"https://www.omie.es/pt/file-download?parents=marginalpibcpt&filename=marginalpibcpt_\" # intradiario\n",
    "\n",
    "data = await download_all_files(base_url, download_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "\n",
    "def parse_plain_text(content):\n",
    "    \"\"\"\n",
    "    Parses plain text data and returns a list of rows.\n",
    "    \"\"\"\n",
    "    # Decode content if it's in bytes\n",
    "    if isinstance(content, bytes):\n",
    "        content = content.decode('utf-8')  # Adjust encoding if necessary\n",
    "\n",
    "    lines = content.strip().split('\\n')\n",
    "    all_rows = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"MARGINALPDBCPT\") or not line.strip():\n",
    "            continue  # Skip header or empty lines\n",
    "        parts = line.split(';')\n",
    "        if len(parts) >= 6:\n",
    "            year, month, day, hour, value1, value2 = parts[:6]\n",
    "            all_rows.append({\n",
    "                \"Year\": year,\n",
    "                \"Month\": month,\n",
    "                \"Day\": day,\n",
    "                \"HourSlot\": hour,\n",
    "                \"PT\": value1,\n",
    "                \"ES\": value2\n",
    "            })\n",
    "    return all_rows\n",
    "\n",
    "def parse_zip_file(content):\n",
    "    \"\"\"\n",
    "    Parses ZIP file data and returns a list of rows by extracting and parsing each `.1` file inside.\n",
    "    \n",
    "    Parameters:\n",
    "    - content (bytes): The binary content of the ZIP file.\n",
    "    \n",
    "    Returns:\n",
    "    - list of dict: Parsed data rows from all `.1` files within the ZIP.\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    with zipfile.ZipFile(BytesIO(content)) as z:\n",
    "        for file_info in z.infolist():\n",
    "            if any(file_info.filename.endswith(f'.{i}') for i in range(1, 10)):\n",
    "                with z.open(file_info) as f:\n",
    "                    file_content = f.read().decode('utf-8')\n",
    "                    all_rows.extend(parse_plain_text(file_content))\n",
    "    return all_rows\n",
    "\n",
    "\n",
    "def process_data(data_dict):\n",
    "    \"\"\"\n",
    "    Process the downloaded data (both .1 and .zip files) and return a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict (dict): A dictionary where keys are file names and values are file contents.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed data with a combined datetime column in UTC.\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    for file_name, content in data_dict.items():\n",
    "        if file_name.endswith(\".zip\"):\n",
    "            all_rows.extend(parse_zip_file(content))\n",
    "        else:\n",
    "            all_rows.extend(parse_plain_text(content))\n",
    "    \n",
    "    # Create DataFrame from all rows\n",
    "    df = pd.DataFrame(all_rows, columns=[\"Year\", \"Month\", \"Day\", \"HourSlot\", \"PT\", \"ES\"])\n",
    "\n",
    "    # Convert appropriate columns to numeric types\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"Month\"] = df[\"Month\"].astype(int)\n",
    "    df[\"Day\"] = df[\"Day\"].astype(int)\n",
    "    df[\"HourSlot\"] = df[\"HourSlot\"].astype(int)  # <-- Modified Line\n",
    "    df[\"PT\"] = pd.to_numeric(df[\"PT\"], errors='raise')\n",
    "    df[\"ES\"] = pd.to_numeric(df[\"ES\"], errors='raise')\n",
    "\n",
    "    df['base_date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "    df.sort_values(by=['base_date', 'HourSlot'], inplace=True)\n",
    "\n",
    "    list_23 = list(range(24))\n",
    "    list_23.remove(2)\n",
    "    list_24 = list(range(24))\n",
    "    list_25 = list(range(24))\n",
    "    list_25.append(2)\n",
    "    list_25.sort()\n",
    "\n",
    "\n",
    "    def _slot_to_hour(group):\n",
    "        group_size = len(group)\n",
    "        if group_size == 23:\n",
    "            group['Hour'] = list_23\n",
    "        elif group_size == 24:\n",
    "            group['Hour'] = list_24\n",
    "        elif group_size == 25:\n",
    "            group['Hour'] = list_25\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return group\n",
    "\n",
    "    df = df.groupby('base_date').apply(_slot_to_hour).reset_index(drop = True)\n",
    "    # print(df[df.base_date==\"20180625\"])\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "        dict(\n",
    "            year=df['Year'],\n",
    "            month=df['Month'],\n",
    "            day=df['Day'],\n",
    "            hour=df['Hour']\n",
    "        ),\n",
    "        errors='raise'  # handle invalid dates if any\n",
    "    )\n",
    "    # print(df[df.datetime==pd.Timestamp(\"2023-10-01\").date()])\n",
    "\n",
    "    df['datetime_cet'] = df['datetime'].dt.tz_localize(\n",
    "        'Europe/Madrid',\n",
    "        # Handle ambiguous times (e.g. fall back):\n",
    "        ambiguous='infer', \n",
    "        # Handle nonexistent times (e.g. spring forward):\n",
    "        nonexistent='raise'\n",
    "    )\n",
    "\n",
    "    # 4) Convert to UTC\n",
    "    df['datetime'] = df['datetime_cet'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "    \n",
    "    # # Drop the separate Year, Month, Day, and Hour columns\n",
    "    df.drop(columns=[\"Year\", \"Month\", \"Day\", \"Hour\", \"HourSlot\", \"base_date\"], inplace=True)\n",
    "    df.drop(columns=[\"datetime_cet\"], inplace=True)\n",
    "\n",
    "    df.set_index(\"datetime\", inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "prices_df = process_data(data)\n",
    "prices_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = prices_df.loc[\"2018-01-01 00:00:00\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fetcher import ENTSOEDataFetcher\n",
    "import nest_asyncio\n",
    "from data_fetcher import SimpleInterval\n",
    "from datetime import datetime\n",
    "from analyzer import analyze\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops (useful for Jupyter notebooks)\n",
    "fetcher = ENTSOEDataFetcher()\n",
    "\n",
    "data_request = SimpleInterval(datetime(2018, 1,1,0), datetime(2024, 12,20,23))\n",
    "fetcher_data = fetcher.get_data(data_request)\n",
    "\n",
    "# Analyze the data to get aggregated and contributions DataFrames\n",
    "aggregated, contributions = analyze(fetcher_data)\n",
    "# aggregated.columns = aggregated.columns.map(lambda x: utils.PSR_TYPE_MAPPING.get(x, x))\n",
    "\n",
    "assert prices_df.index.equals(aggregated.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports = contributions[\"ES\"].add(contributions[\"FR\"], fill_value=0).sum(axis=1, skipna=True)\n",
    "consumption = aggregated.sum(axis=1, skipna=True)\n",
    "\n",
    "percentage_imports = imports.div(consumption)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(percentage_imports, prices_df[\"PT\"], label='Imports/Consumption', color='blue', alpha=0.5, s=1)\n",
    "plt.title('Portuguese imports and price')\n",
    "plt.xlabel('Percentage of imports')\n",
    "plt.ylabel('Price (€/MWh)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "x = percentage_imports\n",
    "y = prices_df[\"PT\"]\n",
    "\n",
    "# Calculate linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, label='Imports/Consumption', color='blue', alpha=0.5, s=1)\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(\n",
    "    x,\n",
    "    intercept + slope * (x),\n",
    "    'r',\n",
    "    label=f'Linear fit: y={slope:.4f}x+{intercept:.2f}, Correlation: {correlation:.2f}'\n",
    ")\n",
    "\n",
    "plt.title('Portuguese imports and price')\n",
    "plt.xlabel('Imports (% of consumption)')\n",
    "plt.ylabel('PT Marginal Spot Price (€/MWh)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "x = imports\n",
    "y = prices_df[\"PT\"]\n",
    "\n",
    "# Calculate linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, label='Imports/Consumption', color='blue', alpha=0.5, s=1)\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(\n",
    "    x,\n",
    "    intercept + slope * (x),\n",
    "    'r',\n",
    "    label=f'Linear fit: y={slope:.4f}x+{intercept:.2f}, Correlation: {correlation:.2f}'\n",
    ")\n",
    "\n",
    "plt.title('Portuguese imports and price')\n",
    "plt.xlabel('Imports')\n",
    "plt.ylabel('PT Marginal Spot Price (€/MWh)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create the violin plot without adding a 'Month' column\n",
    "fig = px.violin(\n",
    "    prices_df,\n",
    "    x=prices_df.index.month,  # Extract month directly from the index\n",
    "    y=\"PT\",\n",
    "    box=True,  # Add a box plot inside the violin\n",
    "    # points=\"all\",  # Show all points\n",
    "    title=\"Distribution of PT Marginal Spot Prices by Month\",\n",
    "    labels={\"x\": \"Month\", \"PT\": \"Price (€/MWh)\"},  # Update x-axis label\n",
    "    template=\"plotly_white\"  # Use a clean white background\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create the violin plot with different colors for each month\n",
    "fig = px.violin(\n",
    "    prices_df,\n",
    "    x=prices_df.index.month,  # Extract month directly from the index\n",
    "    y=\"PT\",\n",
    "    color=prices_df.index.month,  # Use month to assign different colors\n",
    "    box=True,  # Add a box plot inside the violin\n",
    "    # points=\"all\",  # Show all points\n",
    "    title=\"Distribution of PT Marginal Spot Prices by Month\",\n",
    "    labels={\"x\": \"Month\", \"PT\": \"Price (€/MWh)\", \"color\": \"Month\"},  # Update labels\n",
    "    template=\"plotly_white\"  # Use a clean white background\n",
    ")\n",
    "\n",
    "# Adjust the width of the violins\n",
    "for trace in fig.data:\n",
    "    trace.width = 0.8  # Set the desired width\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the violin plot without adding a 'Month' column\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(\n",
    "    x=prices_df.index.month,  # Extract month directly from the index\n",
    "    y=prices_df[\"PT\"],\n",
    "    palette=\"muted\"\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"Distribution of PT Day-Ahead Marginal Spot Prices by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a 2D histogram (density estimate) for the contour plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    x=percentage_imports,\n",
    "    y=prices_df[\"PT\"],\n",
    "    cmap=\"Blues\",  # Color map for the contours\n",
    "    fill=True,  # Fill the contours\n",
    "    thresh=0,  # Show all density levels\n",
    "    levels=20  # Number of contour levels\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Contour Plot: Portuguese Imports vs Price')\n",
    "plt.xlabel('Imports (% of consumption)')\n",
    "plt.ylabel('PT Marginal Spot Price (€/MWh)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a 2D histogram (density estimate) for the contour plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    x=percentage_imports,\n",
    "    y=prices_df[\"PT\"],\n",
    "    cmap=\"Blues\",  # Color map for the contours\n",
    "    fill=True,  # Fill the contours\n",
    "    thresh=0,  # Show all density levels\n",
    "    levels=20,  # Number of contour levels\n",
    "    cbar=True,  # Add a color bar\n",
    "    log_scale=(False, False)  # Logarithmic scale for the color bar\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Contour Plot: Portuguese Imports vs Price (Logarithmic Density)')\n",
    "plt.xlabel('Imports (% of consumption)')\n",
    "plt.ylabel('PT Marginal Spot Price (€/MWh)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
