{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "download_names_list = []\n",
    "\n",
    "start_date = \"20230101\"\n",
    "end_date = \"20241220\"\n",
    "\n",
    "date_list = []\n",
    "current_date = datetime.strptime(start_date, \"%Y%m%d\")\n",
    "end_date_datetime = datetime.strptime(end_date, \"%Y%m%d\")\n",
    "\n",
    "while current_date <= end_date_datetime:\n",
    "    date_list.append(current_date.strftime(\"%Y%m%d\"))\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "for date in date_list:\n",
    "    download_names_list.append(f\"marginalpdbcpt_{date}.1\")\n",
    "\n",
    "years = range(2018, 2023)\n",
    "for year in years:\n",
    "    download_names_list.append(f\"marginalpdbcpt_{year}.zip\")\n",
    "\n",
    "# Replace the .1 with .2 for the specified files\n",
    "for i, name in enumerate(download_names_list):\n",
    "    if name in [\"marginalpdbcpt_20230223.1\", \"marginalpdbcpt_20230528.1\"]:\n",
    "        download_names_list[i] = name.replace('.1', '.2')\n",
    "    if name in [\"marginalpdbcpt_20230121.1\"]:\n",
    "        download_names_list[i] = name.replace('.1', '.3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def download_file(session, url, name):\n",
    "    \"\"\"Download a file from a URL and return its content.\"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Add headers if needed\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            if response.status == 200:\n",
    "                # Read the file content as binary\n",
    "                content = await response.read()\n",
    "                return name, content  # Return the file name and its content\n",
    "            else:\n",
    "                print(f\"Failed to download {url} with status {response.status}\")\n",
    "                return name, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return name, None\n",
    "\n",
    "async def download_all_files(base_url, download_names_list):\n",
    "    \"\"\"Download all files and return a dictionary with file names as keys and content as values.\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [download_file(session, base_url + name, name) for name in download_names_list]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        # Print failed downloads\n",
    "        for name, content in results:\n",
    "            if content is None:\n",
    "                print(f\"Failed to download {name}\")\n",
    "        # Create a dictionary from the results, filtering out failed downloads (None values)\n",
    "        return {name: content for name, content in results if content is not None}\n",
    "\n",
    "# Example usage\n",
    "base_url = \"https://www.omie.es/pt/file-download?parents=marginalpdbcpt&filename=\"\n",
    "\n",
    "data = await download_all_files(base_url, download_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diogo\\AppData\\Local\\Temp\\ipykernel_21712\\1767611469.py:102: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('base_date').apply(_slot_to_hour)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00+00:00</th>\n",
       "      <td>28.10</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00+00:00</th>\n",
       "      <td>33.00</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00+00:00</th>\n",
       "      <td>32.90</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00+00:00</th>\n",
       "      <td>28.10</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00+00:00</th>\n",
       "      <td>27.60</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 18:00:00+00:00</th>\n",
       "      <td>145.39</td>\n",
       "      <td>145.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 19:00:00+00:00</th>\n",
       "      <td>145.38</td>\n",
       "      <td>145.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 20:00:00+00:00</th>\n",
       "      <td>140.01</td>\n",
       "      <td>140.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 21:00:00+00:00</th>\n",
       "      <td>131.98</td>\n",
       "      <td>131.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 22:00:00+00:00</th>\n",
       "      <td>125.68</td>\n",
       "      <td>125.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60672 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PT      ES\n",
       "datetime                                 \n",
       "2017-12-31 23:00:00+00:00   28.10    6.74\n",
       "2018-01-01 00:00:00+00:00   33.00    4.74\n",
       "2018-01-01 01:00:00+00:00   32.90    3.66\n",
       "2018-01-01 02:00:00+00:00   28.10    2.30\n",
       "2018-01-01 03:00:00+00:00   27.60    2.30\n",
       "...                           ...     ...\n",
       "2024-12-20 18:00:00+00:00  145.39  145.39\n",
       "2024-12-20 19:00:00+00:00  145.38  145.38\n",
       "2024-12-20 20:00:00+00:00  140.01  140.01\n",
       "2024-12-20 21:00:00+00:00  131.98  131.98\n",
       "2024-12-20 22:00:00+00:00  125.68  125.68\n",
       "\n",
       "[60672 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "def parse_plain_text(content, file_name):\n",
    "    \"\"\"\n",
    "    Parses plain text data and returns a list of rows.\n",
    "    \"\"\"\n",
    "    # Decode content if it's in bytes\n",
    "    if isinstance(content, bytes):\n",
    "        content = content.decode('utf-8')  # Adjust encoding if necessary\n",
    "\n",
    "    lines = content.strip().split('\\n')\n",
    "    all_rows = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"MARGINALPDBCPT\") or not line.strip():\n",
    "            continue  # Skip header or empty lines\n",
    "        parts = line.split(';')\n",
    "        if len(parts) >= 6:\n",
    "            year, month, day, hour, value1, value2 = parts[:6]\n",
    "            all_rows.append({\n",
    "                \"Year\": year,\n",
    "                \"Month\": month,\n",
    "                \"Day\": day,\n",
    "                \"HourSlot\": hour,\n",
    "                \"PT\": value1,\n",
    "                \"ES\": value2\n",
    "            })\n",
    "    return all_rows\n",
    "\n",
    "def parse_zip_file(content):\n",
    "    \"\"\"\n",
    "    Parses ZIP file data and returns a list of rows by extracting and parsing each `.1` file inside.\n",
    "    \n",
    "    Parameters:\n",
    "    - content (bytes): The binary content of the ZIP file.\n",
    "    \n",
    "    Returns:\n",
    "    - list of dict: Parsed data rows from all `.1` files within the ZIP.\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    with zipfile.ZipFile(BytesIO(content)) as z:\n",
    "        for file_info in z.infolist():\n",
    "            if file_info.filename.endswith('.1'):\n",
    "                with z.open(file_info) as f:\n",
    "                    file_content = f.read().decode('utf-8')\n",
    "                    all_rows.extend(parse_plain_text(file_content, file_info.filename))\n",
    "    return all_rows\n",
    "\n",
    "\n",
    "def process_data(data_dict):\n",
    "    \"\"\"\n",
    "    Process the downloaded data (both .1 and .zip files) and return a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict (dict): A dictionary where keys are file names and values are file contents.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed data with a combined datetime column in UTC.\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    for file_name, content in data_dict.items():\n",
    "        if file_name.endswith(\".zip\"):\n",
    "            all_rows.extend(parse_zip_file(content))\n",
    "        else:\n",
    "            all_rows.extend(parse_plain_text(content, file_name))\n",
    "    \n",
    "    # Create DataFrame from all rows\n",
    "    df = pd.DataFrame(all_rows, columns=[\"Year\", \"Month\", \"Day\", \"HourSlot\", \"PT\", \"ES\"])\n",
    "    \n",
    "    # Convert appropriate columns to numeric types\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"Month\"] = df[\"Month\"].astype(int)\n",
    "    df[\"Day\"] = df[\"Day\"].astype(int)\n",
    "    df[\"HourSlot\"] = df[\"HourSlot\"].astype(int)  # <-- Modified Line\n",
    "    df[\"PT\"] = pd.to_numeric(df[\"PT\"], errors='raise')\n",
    "    df[\"ES\"] = pd.to_numeric(df[\"ES\"], errors='raise')\n",
    "\n",
    "\n",
    "    df['base_date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "    df.sort_values(by=['base_date', 'HourSlot'], inplace=True)\n",
    "\n",
    "    list_23 = list(range(24))\n",
    "    list_23.remove(2)\n",
    "    list_24 = list(range(24))\n",
    "    list_25 = list(range(24))\n",
    "    list_25.append(2)\n",
    "    list_25.sort()\n",
    "    def _slot_to_hour(group):\n",
    "        group_size = len(group)\n",
    "        if group_size == 23:\n",
    "            group['Hour'] = list_23\n",
    "        elif group_size == 24:\n",
    "            group['Hour'] = list_24\n",
    "        elif group_size == 25:\n",
    "            group['Hour'] = list_25\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return group\n",
    "\n",
    "    df = df.groupby('base_date').apply(_slot_to_hour)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(\n",
    "        dict(\n",
    "            year=df['Year'],\n",
    "            month=df['Month'],\n",
    "            day=df['Day'],\n",
    "            hour=df['Hour']\n",
    "        ),\n",
    "        errors='raise'  # handle invalid dates if any\n",
    "    )\n",
    "    # target_day = pd.Timestamp('2018-10-28').date()\n",
    "    # filtered_df = df[df['datetime'].dt.date == target_day]\n",
    "    # print(filtered_df)\n",
    "    # target_day = pd.Timestamp('2018-10-29').date()\n",
    "    # filtered_df = df[df['datetime'].dt.date == target_day]\n",
    "    # print(filtered_df)\n",
    "\n",
    "    df['datetime'] = df['datetime'].dt.tz_localize(\n",
    "        'CET',\n",
    "        # Handle ambiguous times (e.g. fall back):\n",
    "        ambiguous='infer', \n",
    "        # Handle nonexistent times (e.g. spring forward):\n",
    "        # nonexistent='shift_forward'\n",
    "    )\n",
    "\n",
    "    # 4) Convert to UTC\n",
    "    df['datetime'] = df['datetime'].dt.tz_convert('UTC')\n",
    "    \n",
    "    # # Drop the separate Year, Month, Day, and Hour columns\n",
    "    df.drop(columns=[\"Year\", \"Month\", \"Day\", \"Hour\", \"HourSlot\", \"base_date\"], inplace=True)\n",
    "\n",
    "    df.set_index(\"datetime\", inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = process_data(data)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04506197257383966)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"Value1\"] != df[\"Value2\"]).sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "flow_es_to_pt = pd.read_pickle(\"../.data_cache/flow_es_to_pt.pkl.gz\")\n",
    "flow_pt_to_es = pd.read_pickle(\"../.data_cache/flow_pt_to_es.pkl.gz\")\n",
    "flow_fr_to_es = pd.read_pickle(\"../.data_cache/flow_fr_to_es.pkl.gz\")\n",
    "flow_es_to_fr = pd.read_pickle(\"../.data_cache/flow_es_to_fr.pkl.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
